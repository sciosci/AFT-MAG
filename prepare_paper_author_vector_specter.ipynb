{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper [SPECTER](https://github.com/allenai/specter) vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Papers to get their vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import simplejson as json\n",
    "\n",
    "def write_todo():\n",
    "    \"\"\"\"\"\"\n",
    "    authorship_df = pd.read_csv('dataset/authorship.csv', dtype=str, columns=['MAGPaperID'])\n",
    "    print(authorship_df.shape)\n",
    "    mag_paper_specter = pd.read_parquet('results/paper_specter.parquet', columns=['ids'])\n",
    "    mag_paper_specter['ids'] = mag_paper_specter.ids.astype(str)\n",
    "    print(mag_paper_specter.shape)\n",
    "    todo = set(authorship_df['MAGPaperID']) - set(mag_paper_specter['ids'])\n",
    "    print(len(todo))\n",
    "    fout = open('specter_todo.json', 'w')\n",
    "    for line in open('results/mag_title_abstract.json'):\n",
    "        pubid, title, abstract = json.loads(line)\n",
    "        if pubid in todo:\n",
    "            fout.write(line)\n",
    "    fout.close()\n",
    "\n",
    "write_todo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import simplejson as json\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def embed_batch(tokenizer, model, pickler, pubids, batch):\n",
    "    \"\"\"\"\"\"\n",
    "    inputs = tokenizer(batch, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    result = model(**inputs)\n",
    "    vec = result.last_hidden_state[:, 0, :].detach().cpu().numpy()\n",
    "    for a, b in zip(pubids, vec):\n",
    "        pickler.dump([a, b])\n",
    "\n",
    "def embed_chunk(out_path, already):\n",
    "    \"\"\"\"\"\"\n",
    "    fout = open(out_path, 'ab')\n",
    "    pickler = pickle.Pickler(fout)\n",
    "    tokenizer = AutoTokenizer.from_pretrained('allenai/specter')\n",
    "    model = AutoModel.from_pretrained('allenai/specter')\n",
    "    pubids, batch = [], []\n",
    "    cnt = 0\n",
    "    for line in open('specter_todo.json'):\n",
    "        pubid, title, abstract = json.loads(line)\n",
    "        if pubid in already:\n",
    "            continue\n",
    "        pubids.append(pubid)\n",
    "        batch.append(title + ' ' + abstract)\n",
    "        if len(pubids) == 8:\n",
    "            embed_batch(tokenizer, model, pickler, pubids, batch)\n",
    "            pubids, batch = [], []\n",
    "            cnt += 8\n",
    "        if cnt % 1000 == 0:\n",
    "            print(cnt, end='')\n",
    "            print('\\r', end='')\n",
    "    if len(pubids) > 0:\n",
    "        embed_batch(tokenizer, model, pickler, pubids, batch)\n",
    "        cnt += len(pubids)\n",
    "    return cnt\n",
    "\n",
    "def embed_all():\n",
    "    \"\"\"\"\"\"\n",
    "    out_path = 'results/paper_specter_2.pkl'\n",
    "    already = set()\n",
    "    if os.path.exists(out_path):\n",
    "        fin = open(out_path, 'rb')\n",
    "        unpickler = pickle.Unpickler(fin) \n",
    "        while True:\n",
    "            try:\n",
    "                data = unpickler.load()\n",
    "            except EOFError:\n",
    "                break\n",
    "            already.add(data[0])\n",
    "        fin.close()\n",
    "    print(len(already))\n",
    "    cnt = embed_chunk(out_path, already)\n",
    "\n",
    "embed_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_paper_specter():\n",
    "    \"\"\"\"\"\"\n",
    "    results = []\n",
    "    in_paths = [f for f in os.listdir('results/') if isfile(join('results/', f)) and 'paper_specter' in f]\n",
    "    for in_path in in_paths:\n",
    "        print(in_path)\n",
    "        in_path = join('results/', in_path)\n",
    "        if in_path.endswith('.parquet'):\n",
    "            df = pd.read_parquet(in_path)\n",
    "            df['ids'] = df.ids.astype(str)\n",
    "            results.append(df)\n",
    "        elif in_path.endswith('.pkl'):\n",
    "            rows = []\n",
    "            fin = open(in_path, 'rb')\n",
    "            unpickler = pickle.Unpickler(fin)\n",
    "            while True:\n",
    "                try:\n",
    "                    pub_id, vec = unpickler.load()\n",
    "                    rows.append([vec, pub_id])\n",
    "                except EOFError:\n",
    "                    break\n",
    "            fin.close()\n",
    "            results.append(pd.DataFrame(rows, columns=['embedding', 'ids']))\n",
    "    return pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_paper_specter():\n",
    "    \"\"\"\"\"\"\n",
    "    mag_paper_specter = load_paper_specter()\n",
    "    print(mag_paper_specter.shape)\n",
    "    mag_pub_ids = set(pd.read_csv('dataset/authorship.csv', dtype=str)['MAGPaperID'])\n",
    "    print(len(mag_pub_ids))\n",
    "    cnt = 0\n",
    "    for idx, df_i in enumerate(np.array_split(mag_paper_specter, 10)):\n",
    "        fout = open('dataset/paper_specter_%d.pkl' % idx, 'wb')\n",
    "        pickler = pickle.Pickler(fout)\n",
    "        for pub_id, vec in zip(*[df_i[c] for c in ['ids', 'embedding']]):\n",
    "            if pub_id in mag_pub_ids:\n",
    "                pickler.dump([pub_id, vec])\n",
    "                cnt += 1\n",
    "        fout.close()\n",
    "    print(cnt) # 16942415\n",
    "\n",
    "split_paper_specter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author SPECTER vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from os.path import isfile, join\n",
    "\n",
    "def load_paper_specter():\n",
    "    \"\"\"\"\"\"\n",
    "    rows = []\n",
    "    in_paths = sorted(f for f in os.listdir('dataset/') if isfile(join('dataset/', f)) and 'paper_specter_' in f)\n",
    "    for in_path in in_paths:\n",
    "        print(in_path)\n",
    "        in_path = join('dataset/', in_path)\n",
    "        fin = open(in_path, 'rb')\n",
    "        unpickler = pickle.Unpickler(fin)\n",
    "        while True:\n",
    "            try:\n",
    "                rows.append(unpickler.load())\n",
    "            except EOFError:\n",
    "                break\n",
    "        fin.close()\n",
    "    return pd.DataFrame(rows, columns=['MAGPaperID', 'SpecterVector'])\n",
    "\n",
    "def write_author_vector_specter():\n",
    "    \"\"\"\"\"\"\n",
    "    mag_paper_specter = load_paper_specter()\n",
    "    print(mag_paper_specter.shape)\n",
    "    pubid_to_idx = {p: i for i, p in enumerate(mag_paper_specter.MAGPaperID)}\n",
    "    print(len(pubid_to_idx))\n",
    "    pid_to_mag_pubids = pd.read_csv(\n",
    "        'dataset/authorship.csv', dtype=str).groupby('PID')['MAGPaperID'].apply(set).to_dict()\n",
    "    print(len(pid_to_mag_pubids))\n",
    "    fout = open('dataset/researcher_specter.pkl', 'wb')\n",
    "    pickler = pickle.Pickler(fout)\n",
    "    cnt = 0\n",
    "    for pid in sorted(pid_to_mag_pubids, key=lambda x: int(x)):\n",
    "        pubs = pid_to_mag_pubids[pid]\n",
    "        indices = sorted(pubid_to_idx[p] for p in pubs)\n",
    "        vec = np.vstack(mag_paper_specter.iloc[indices].SpecterVector.values).mean(axis=0)\n",
    "        pickler.dump([pid, vec])\n",
    "        cnt += 1\n",
    "    fout.close()\n",
    "    print(cnt) # 494455\n",
    "\n",
    "write_author_vector_specter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
